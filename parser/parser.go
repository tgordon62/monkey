// Pratt parser for the Monkey programming language.
package parser

import (
	"fmt"
	"monkey-interpreter/ast"
	"monkey-interpreter/lexer"
	"monkey-interpreter/token"
	"strconv"
)

// Structure of a parser instance.
type Parser struct {
	lex       *lexer.Lexer
	errors    []string
	curToken  token.Token
	peekToken token.Token

	prefixParseFns map[token.TokenType]prefixParseFn
	infixParseFns  map[token.TokenType]infixParseFn
}

// Function types which correspond to token positions.
type (
	prefixParseFn func() ast.Expression
	infixParseFn  func(ast.Expression) ast.Expression
)

const (
	_ int = iota
	LOWEST
	EQUALS      // ==
	LESSGREATER // > or <
	SUM         // +
	PRODUCT     // *
	PREFIX      // -X or !X
	CALL        // myFunction(X)
)

var precedences = map[token.TokenType]int{
	token.EQ:       EQUALS,
	token.NOT_EQ:   EQUALS,
	token.LT:       LESSGREATER,
	token.GT:       LESSGREATER,
	token.PLUS:     SUM,
	token.MINUS:    SUM,
	token.SLASH:    PRODUCT,
	token.ASTERISK: PRODUCT,
}

// Create a new parser instance and reutrn it. Accepts a Lexer instance
// which will be parsed.
func New(lex *lexer.Lexer) *Parser {
	par := &Parser{
		lex:    lex,
		errors: []string{},
	}

	par.prefixParseFns = make(map[token.TokenType]prefixParseFn)
	par.infixParseFns = make(map[token.TokenType]infixParseFn)

	// Add parsing functions to maps
	par.registerPrefix(token.IDENT, par.parseIdentifier)
	par.registerPrefix(token.INT, par.parseIntegerLiteral)
	par.registerPrefix(token.BANG, par.parsePrefixExpression)
	par.registerPrefix(token.MINUS, par.parsePrefixExpression)
	par.registerPrefix(token.TRUE, par.parseBoolean)
	par.registerPrefix(token.FALSE, par.parseBoolean)

	par.registerInfix(token.PLUS, par.parseInfixExpression)
	par.registerInfix(token.MINUS, par.parseInfixExpression)
	par.registerInfix(token.SLASH, par.parseInfixExpression)
	par.registerInfix(token.ASTERISK, par.parseInfixExpression)
	par.registerInfix(token.EQ, par.parseInfixExpression)
	par.registerInfix(token.NOT_EQ, par.parseInfixExpression)
	par.registerInfix(token.LT, par.parseInfixExpression)
	par.registerInfix(token.GT, par.parseInfixExpression)

	// Read two tokens, so curToken and peekToken are both set
	par.nextToken()
	par.nextToken()

	return par
}

// Parse the tokens generated by the Lexer.
func (par *Parser) ParseProgram() *ast.Program {
	program := &ast.Program{}
	program.Statements = []ast.Statement{}

	for !par.curTokenIs(token.EOF) {
		stmt := par.parseStatement()
		if stmt != nil {
			program.Statements = append(program.Statements, stmt)
		}
		par.nextToken()
	}

	return program
}

// Parse an entire statement beginning with either a 'let' or 'return' keyword.
func (par *Parser) parseStatement() ast.Statement {
	switch par.curToken.Type {
	case token.LET:
		return par.parseLetStatement()
	case token.RETURN:
		return par.parseReturnStatement()
	default:
		return par.parseExpressionStatement()
	}
}

// Parse a statement beginning with a 'let' keyword.
func (par *Parser) parseLetStatement() *ast.LetStatement {
	stmt := &ast.LetStatement{Token: par.curToken}

	if !par.expectPeek(token.IDENT) {
		return nil
	}

	stmt.Name = &ast.Identifier{Token: par.curToken, Value: par.curToken.Literal}

	if !par.expectPeek(token.ASSIGN) {
		return nil
	}

	// TODO: We're skipping the expressions until we
	// encounter a semicolon
	for !par.curTokenIs(token.SEMICOLON) {
		par.nextToken()
	}

	return stmt
}

// Parse a statement beginning with a 'return' keyword.
func (par *Parser) parseReturnStatement() *ast.ReturnStatement {
	stmt := &ast.ReturnStatement{Token: par.curToken}

	par.nextToken()

	// TODO: We're skipping the expressions until we
	// encounter a semicolon
	for !par.curTokenIs(token.SEMICOLON) {
		par.nextToken()
	}

	return stmt
}

// Parse an expression statement.
func (par *Parser) parseExpressionStatement() ast.Statement {
	// defer untrace(trace("parseExpressionStatement"))

	stmt := &ast.ExpressionStatement{Token: par.curToken}
	stmt.Expression = par.parseExpression(LOWEST)

	if par.peekTokenIs(token.SEMICOLON) {
		par.nextToken()
	}

	return stmt
}

// Parse an expression.
func (par *Parser) parseExpression(precedence int) ast.Expression {
	// defer untrace(trace("parseExpression"))

	prefix := par.prefixParseFns[par.curToken.Type]
	if prefix == nil {
		par.noPrefixParseFnError(par.curToken.Type)
		return nil
	}
	leftExp := prefix()

	for !par.peekTokenIs(token.SEMICOLON) && precedence < par.peekPrecedence() {
		infix := par.infixParseFns[par.peekToken.Type]
		if infix == nil {
			return leftExp
		}

		par.nextToken()

		leftExp = infix(leftExp)
	}

	return leftExp
}

// Parse an expression with a prefix operator.
func (par *Parser) parsePrefixExpression() ast.Expression {
	// defer untrace(trace("parsePrefixExpression"))

	expression := &ast.PrefixExpression{
		Token:    par.curToken,
		Operator: par.curToken.Literal,
	}

	par.nextToken()

	expression.Right = par.parseExpression(PREFIX)

	return expression
}

// Parse an expression with an infix operator
func (par *Parser) parseInfixExpression(left ast.Expression) ast.Expression {
	// defer untrace(trace("parseInfixExpression"))

	expression := &ast.InfixExpression{
		Token:    par.curToken,
		Operator: par.curToken.Literal,
		Left:     left,
	}

	precedence := par.curPrecedence()
	par.nextToken()
	expression.Right = par.parseExpression(precedence)

	return expression
}

// Parse an identifier.
func (par *Parser) parseIdentifier() ast.Expression {
	return &ast.Identifier{Token: par.curToken, Value: par.curToken.Literal}
}

// Parse an integer literal.
func (par *Parser) parseIntegerLiteral() ast.Expression {
	// defer untrace(trace("parseIntegerLiteral"))

	lit := &ast.IntegerLiteral{Token: par.curToken}

	value, err := strconv.ParseInt(par.curToken.Literal, 0, 64)
	if err != nil {
		msg := fmt.Sprintf("could not parse %q as integer", par.curToken.Literal)
		par.errors = append(par.errors, msg)
		return nil
	}

	lit.Value = value

	return lit
}

// Parse a boolean.
func (par *Parser) parseBoolean() ast.Expression {
	return &ast.Boolean{Token: par.curToken, Value: par.curTokenIs(token.TRUE)}
}

// Update the current token of the parser instace to the peek token, and then
// update the peek token to the next token from the Lexer.
func (par *Parser) nextToken() {
	par.curToken = par.peekToken
	par.peekToken = par.lex.NextToken()
}

// Confirm that the Parser's current token is the same type as the parameter tok.
func (par *Parser) curTokenIs(tok token.TokenType) bool {
	return par.curToken.Type == tok
}

// Confirm that the Parser's peek token is the same type as the parameter tok.
func (par *Parser) peekTokenIs(tok token.TokenType) bool {
	return par.peekToken.Type == tok
}

// Confirm that the Parser's peek token is the same type as the parameter tok.
// If it is, then the parser will proceed to the next token. If it is not, the
// function will log an error.
func (par *Parser) expectPeek(tok token.TokenType) bool {
	if par.peekTokenIs(tok) {
		par.nextToken()
		return true
	} else {
		par.peekError(tok)
		return false
	}
}

func (p *Parser) curPrecedence() int {
	if p, ok := precedences[p.curToken.Type]; ok {
		return p
	}

	return LOWEST
}

func (p *Parser) peekPrecedence() int {
	if p, ok := precedences[p.peekToken.Type]; ok {
		return p
	}

	return LOWEST
}

// Add a function for parsing prefix operators to the prefixParseFns map.
func (p *Parser) registerPrefix(tokenType token.TokenType, fn prefixParseFn) {
	p.prefixParseFns[tokenType] = fn
}

// Add a function for parsing infix operators to the infixParseFns map.
func (p *Parser) registerInfix(tokenType token.TokenType, fn infixParseFn) {
	p.infixParseFns[tokenType] = fn
}

// Return the log of errors generated while parsing.
func (par *Parser) Errors() []string {
	return par.errors
}

// Log an error signifyiing that the expected next token was not found.
func (par *Parser) peekError(tok token.TokenType) {
	msg := fmt.Sprintf("Expected next token to be %s, got %s instead",
		tok, par.peekToken.Type)
	par.errors = append(par.errors, msg)
}

// Log an error signifying that the prefix operator found has no corresponding parser.
func (par *Parser) noPrefixParseFnError(t token.TokenType) {
	msg := fmt.Sprintf("no prefix parse function for %s found", t)
	par.errors = append(par.errors, msg)
}
